{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a60486d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc127608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# (RE-USE) Load Data\n",
    "# =============================================================================\n",
    "def load_detailed_results():\n",
    "    \"\"\"\n",
    "    Same as your original function: loads MRegularSeasonDetailedResults + MNCAATourneyDetailedResults,\n",
    "    creates a GameID, WinMargin, LoseMargin, etc.\n",
    "    \"\"\"\n",
    "    reg_detailed = pd.read_csv('Data/WRegularSeasonDetailedResults.csv')\n",
    "    tourney_detailed = pd.read_csv('Data/WNCAATourneyDetailedResults.csv')\n",
    "    \n",
    "    all_games = pd.concat([reg_detailed, tourney_detailed], ignore_index=True)\n",
    "    all_games['GameID'] = all_games.apply(\n",
    "        lambda row: f\"{row['Season']}_{min(row['WTeamID'], row['LTeamID'])}_{max(row['WTeamID'], row['LTeamID'])}_{row['DayNum']}\",\n",
    "        axis=1\n",
    "    )\n",
    "    all_games['WinMargin'] = all_games['WScore'] - all_games['LScore']\n",
    "    all_games['LoseMargin'] = all_games['LScore'] - all_games['WScore']\n",
    "    \n",
    "    return all_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1d73eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# (RE-USE) Transform to long format\n",
    "# =============================================================================\n",
    "def transform_to_long(all_games):\n",
    "    \"\"\"\n",
    "    Same as your original function:\n",
    "    Turns each game into two rows (winner, loser) from each team's perspective.\n",
    "    \"\"\"\n",
    "    win_cols = [\n",
    "        'GameID','Season','DayNum',\n",
    "        'WTeamID','WScore','WFGM','WFGA','WFGM3','WFGA3','WFTM','WFTA',\n",
    "        'WOR','WDR','WAst','WTO','WStl','WBlk','WPF','WinMargin'\n",
    "    ]\n",
    "    lose_cols = [\n",
    "        'GameID','Season','DayNum',\n",
    "        'LTeamID','LScore','LFGM','LFGA','LFGM3','LFGA3','LFTM','LFTA',\n",
    "        'LOR','LDR','LAst','LTO','LStl','LBlk','LPF','LoseMargin'\n",
    "    ]\n",
    "    \n",
    "    wins = all_games[win_cols].copy()\n",
    "    wins.rename(columns={\n",
    "        'WTeamID':'TeamID',\n",
    "        'WScore':'Score',\n",
    "        'WFGM':'FGM',\n",
    "        'WFGA':'FGA',\n",
    "        'WFGM3':'FGM3',\n",
    "        'WFGA3':'FGA3',\n",
    "        'WFTM':'FTM',\n",
    "        'WFTA':'FTA',\n",
    "        'WOR':'OR',\n",
    "        'WDR':'DR',\n",
    "        'WAst':'Ast',\n",
    "        'WTO':'TO',\n",
    "        'WStl':'Stl',\n",
    "        'WBlk':'Blk',\n",
    "        'WPF':'PF',\n",
    "        'WinMargin':'Margin'\n",
    "    }, inplace=True)\n",
    "    wins['Win'] = 1\n",
    "    \n",
    "    losses = all_games[lose_cols].copy()\n",
    "    losses.rename(columns={\n",
    "        'LTeamID':'TeamID',\n",
    "        'LScore':'Score',\n",
    "        'LFGM':'FGM',\n",
    "        'LFGA':'FGA',\n",
    "        'LFGM3':'FGM3',\n",
    "        'LFGA3':'FGA3',\n",
    "        'LFTM':'FTM',\n",
    "        'LFTA':'FTA',\n",
    "        'LOR':'OR',\n",
    "        'LDR':'DR',\n",
    "        'LAst':'Ast',\n",
    "        'LTO':'TO',\n",
    "        'LStl':'Stl',\n",
    "        'LBlk':'Blk',\n",
    "        'LPF':'PF',\n",
    "        'LoseMargin':'Margin'\n",
    "    }, inplace=True)\n",
    "    losses['Win'] = 0\n",
    "    \n",
    "    long_df = pd.concat([wins, losses], ignore_index=True)\n",
    "    return long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a7cdeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# (RE-USE) \"Last n games\" window features\n",
    "# =============================================================================\n",
    "def process_last_n_games_window(group, n=7):\n",
    "    \"\"\"\n",
    "    Same as your original function: For each row in (Season,TeamID)'s data (sorted by DayNum),\n",
    "    gather the prior n games, compute various rolling averages & clutch stats.\n",
    "    \"\"\"\n",
    "    group = group.sort_values('DayNum').reset_index(drop=True)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(len(group)):\n",
    "        prior_games = group.iloc[max(0, i-n):i]\n",
    "        if len(prior_games) < n:\n",
    "            # Not enough prior games\n",
    "            results.append({\n",
    "                'window_games':                np.nan,\n",
    "                'window_score_avg':            np.nan,\n",
    "                'window_FG_pct':               np.nan,\n",
    "                'window_3P_pct':               np.nan,\n",
    "                'window_FT_pct':               np.nan,\n",
    "                'window_off_eff':              np.nan,\n",
    "                'window_Ast_avg':              np.nan,\n",
    "                'window_TO_avg':               np.nan,\n",
    "                'window_Stl_avg':              np.nan,\n",
    "                'window_Blk_avg':              np.nan,\n",
    "                'window_PF_avg':               np.nan,\n",
    "                'window_OR_avg':               np.nan,\n",
    "                'window_DR_avg':               np.nan,\n",
    "                'window_clutch_count':         np.nan,\n",
    "                'window_clutch_win_pct':       np.nan,\n",
    "                'window_clutch_margin_avg':    np.nan,\n",
    "                'window_clutch_score_avg':     np.nan\n",
    "            })\n",
    "        else:\n",
    "            sum_FGM  = prior_games['FGM'].sum()\n",
    "            sum_FGA  = prior_games['FGA'].sum()\n",
    "            FG_pct   = sum_FGM / sum_FGA if sum_FGA>0 else np.nan\n",
    "\n",
    "            sum_FGM3 = prior_games['FGM3'].sum()\n",
    "            sum_FGA3 = prior_games['FGA3'].sum()\n",
    "            FG3_pct  = sum_FGM3 / sum_FGA3 if sum_FGA3>0 else np.nan\n",
    "\n",
    "            sum_FTM  = prior_games['FTM'].sum()\n",
    "            sum_FTA  = prior_games['FTA'].sum()\n",
    "            FT_pct   = sum_FTM / sum_FTA if sum_FTA>0 else np.nan\n",
    "\n",
    "            total_points = 2*(sum_FGM - sum_FGM3) + 3*sum_FGM3 + sum_FTM\n",
    "            total_poss   = sum_FGA - prior_games['OR'].sum() + prior_games['TO'].sum() + 0.44*sum_FTA\n",
    "            off_eff      = total_points / total_poss if total_poss>0 else np.nan\n",
    "\n",
    "            score_avg    = prior_games['Score'].mean()\n",
    "            Ast_avg      = prior_games['Ast'].mean()\n",
    "            TO_avg       = prior_games['TO'].mean()\n",
    "            Stl_avg      = prior_games['Stl'].mean()\n",
    "            Blk_avg      = prior_games['Blk'].mean()\n",
    "            PF_avg       = prior_games['PF'].mean()\n",
    "            OR_avg       = prior_games['OR'].mean()\n",
    "            DR_avg       = prior_games['DR'].mean()\n",
    "\n",
    "            # Clutch performance\n",
    "            clutch_filter = prior_games['Margin'].abs() <= 5\n",
    "            clutch_games  = prior_games[clutch_filter]\n",
    "            clutch_count  = len(clutch_games)\n",
    "            if clutch_count == 0:\n",
    "                clutch_win_pct      = 0.0\n",
    "                clutch_margin_avg   = 0.0\n",
    "                clutch_score_avg    = 0.0\n",
    "            else:\n",
    "                clutch_win_pct      = clutch_games['Win'].mean()\n",
    "                clutch_margin_avg   = clutch_games['Margin'].mean()\n",
    "                clutch_score_avg    = clutch_games['Score'].mean()\n",
    "\n",
    "            results.append({\n",
    "                'window_games':                len(prior_games),\n",
    "                'window_score_avg':            score_avg,\n",
    "                'window_FG_pct':               FG_pct,\n",
    "                'window_3P_pct':               FG3_pct,\n",
    "                'window_FT_pct':               FT_pct,\n",
    "                'window_off_eff':              off_eff,\n",
    "                'window_Ast_avg':              Ast_avg,\n",
    "                'window_TO_avg':               TO_avg,\n",
    "                'window_Stl_avg':              Stl_avg,\n",
    "                'window_Blk_avg':              Blk_avg,\n",
    "                'window_PF_avg':               PF_avg,\n",
    "                'window_OR_avg':               OR_avg,\n",
    "                'window_DR_avg':               DR_avg,\n",
    "                'window_clutch_count':         clutch_count,\n",
    "                'window_clutch_win_pct':       clutch_win_pct,\n",
    "                'window_clutch_margin_avg':    clutch_margin_avg,\n",
    "                'window_clutch_score_avg':     clutch_score_avg\n",
    "            })\n",
    "    \n",
    "    window_df = pd.DataFrame(results)\n",
    "    return pd.concat([group, window_df], axis=1)\n",
    "\n",
    "def compute_7game_window_features(long_df, n=7):\n",
    "    \"\"\"\n",
    "    Group by (Season,TeamID) and apply the \"last n games\" function above.\n",
    "    \"\"\"\n",
    "    return long_df.groupby(['Season','TeamID'], group_keys=False).apply(\n",
    "        lambda grp: process_last_n_games_window(grp, n=n)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b644ec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_7game_clutch_dataset_test(long_df_window, sample_submission_path='SampleSubmissionStage2.csv'):\n",
    "    \"\"\"\n",
    "    Given the 7-game window stats for ALL 2025 regular-season games (i.e. long_df_window),\n",
    "    read the tournament matchups from SampleSubmissionStage2.csv, parse the TeamIDs,\n",
    "    fetch each team's final window stats, and compute the same \"diff\" columns\n",
    "    as in your training set. Return a DataFrame with the same feature columns.\n",
    "\n",
    "    NOTE: We skip any matchup where either side has fewer than 7 prior games\n",
    "          (i.e. window_games != 7).\n",
    "    \"\"\"\n",
    "    # Load sample submission (Stage2)\n",
    "    sub = pd.read_csv(sample_submission_path)\n",
    "    \n",
    "    # Example: ID == \"2025_1104_1277\", so parse out season, team1, team2\n",
    "    def parse_id(s):\n",
    "        # each ID is \"Season_TeamA_TeamB\"\n",
    "        parts = s.split('_')\n",
    "        return int(parts[0]), int(parts[1]), int(parts[2])\n",
    "    \n",
    "    sub[['Season','Team1','Team2']] = sub['ID'].apply(\n",
    "        lambda x: pd.Series(parse_id(x))\n",
    "    )\n",
    "    \n",
    "    # Keep only 2025\n",
    "    sub = sub[sub['Season'] == 2025].copy()\n",
    "    \n",
    "    # Identify which is LowerTeamID vs HigherTeamID\n",
    "    sub['LowerTeamID'] = sub[['Team1','Team2']].min(axis=1)\n",
    "    sub['HigherTeamID'] = sub[['Team1','Team2']].max(axis=1)\n",
    "      \n",
    "    reg_2025 = long_df_window.query(\"Season == 2025 and DayNum <= 132\").copy()\n",
    "    \n",
    "    # Now group by TeamID, pick the last row by DayNum\n",
    "    # (This row has that team’s final 7-game window stats heading into the tourney.)\n",
    "    last_stats = (\n",
    "        reg_2025.sort_values('DayNum')\n",
    "                .groupby(['Season','TeamID'], as_index=False)\n",
    "                .last()\n",
    "    )\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    # Merge 'last_stats' onto sub, once for the \"lower\" side, once for the \"higher\" side\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # We want suffixes that keep the columns separate so we can do diffs\n",
    "    lower_merged = sub.merge(\n",
    "        last_stats,\n",
    "        how='left',\n",
    "        left_on=['Season','LowerTeamID'],\n",
    "        right_on=['Season','TeamID'],\n",
    "        suffixes=(None, '_lower')\n",
    "    )\n",
    "    # rename columns to keep them consistent\n",
    "    for c in ['TeamID','Score','FGA','FGM','FGA3','FGM3','FTA','FTM','OR','DR','Ast','TO','Stl','Blk','PF','Margin','Win']:\n",
    "        if c in lower_merged.columns:\n",
    "            lower_merged.drop(columns=c, inplace=True)  # not needed for the final diffs\n",
    "    \n",
    "    # Do a second merge for the \"higher\" side\n",
    "    higher_merged = sub.merge(\n",
    "        last_stats,\n",
    "        how='left',\n",
    "        left_on=['Season','HigherTeamID'],\n",
    "        right_on=['Season','TeamID'],\n",
    "        suffixes=(None, '_higher')\n",
    "    )\n",
    "    for c in ['TeamID','Score','FGA','FGM','FGA3','FGM3','FTA','FTM','OR','DR','Ast','TO','Stl','Blk','PF','Margin','Win']:\n",
    "        if c in higher_merged.columns:\n",
    "            higher_merged.drop(columns=c, inplace=True)\n",
    "    \n",
    "    # Now combine them side by side\n",
    "    # We'll keep the main submission columns from lower_merged, then append the higher_ suffix columns\n",
    "    merged = lower_merged.merge(\n",
    "        higher_merged.drop(['ID','Season','Team1','Team2','LowerTeamID','HigherTeamID'], axis=1),\n",
    "        how='left',\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        suffixes=('', '_higher')\n",
    "    )\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    # Build the exact same \"diff\" features you used in training\n",
    "    #--------------------------------------------------------------------------------\n",
    "    window_cols = [\n",
    "        'window_score_avg','window_FG_pct','window_3P_pct','window_FT_pct','window_off_eff',\n",
    "        'window_Ast_avg','window_TO_avg','window_Stl_avg','window_Blk_avg','window_PF_avg',\n",
    "        'window_OR_avg','window_DR_avg','window_clutch_count','window_clutch_win_pct',\n",
    "        'window_clutch_margin_avg','window_clutch_score_avg'\n",
    "    ]\n",
    "    \n",
    "    # We will create new columns \"xxx_diff\" = (lower - higher)\n",
    "    for col in window_cols:\n",
    "        lower_col  = col\n",
    "        higher_col = col + '_higher'\n",
    "        diff_col   = col + '_diff'\n",
    "        merged[diff_col] = merged[lower_col] - merged[higher_col]\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    # Filter out rows where either side does NOT have a full 7-game window\n",
    "    # (just like in training, skip if window_games != 7)\n",
    "    #--------------------------------------------------------------------------------\n",
    "    merged = merged[(merged['window_games'] == 7) & (merged['window_games_higher'] == 7)]\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    # Final test DataFrame: same columns as training, minus 'Target'\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # In your training set, you had columns:\n",
    "    #   Season, LowerTeamID, HigherTeamID, Target, and all the \"_diff\" columns\n",
    "    # We keep those but no Target for test.\n",
    "    \n",
    "    diff_cols = [c for c in merged.columns if c.endswith('_diff')]\n",
    "    final_test = merged[['ID','Season','LowerTeamID','HigherTeamID'] + diff_cols].copy()\n",
    "    \n",
    "    return final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "115aa86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and combine detailed results.\n",
    "all_games = load_detailed_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "410d62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Transform to long format.\n",
    "long_df = transform_to_long(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f3e185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute recent 7-day window features.\n",
    "long_df_window = compute_7game_window_features(long_df, n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd26313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build the matchup dataset based on these recent window features.\n",
    "test_dataset_2025 = build_7game_clutch_dataset_test(\n",
    "        long_df_window, \n",
    "        sample_submission_path='Data/SampleSubmissionStage2.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b82a700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"Data/SampleSubmissionStage2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06eba25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66066</th>\n",
       "      <td>2025_3101_3102</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66067</th>\n",
       "      <td>2025_3101_3103</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66068</th>\n",
       "      <td>2025_3101_3104</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66069</th>\n",
       "      <td>2025_3101_3105</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66070</th>\n",
       "      <td>2025_3101_3106</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131402</th>\n",
       "      <td>2025_3477_3479</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131403</th>\n",
       "      <td>2025_3477_3480</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131404</th>\n",
       "      <td>2025_3478_3479</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131405</th>\n",
       "      <td>2025_3478_3480</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131406</th>\n",
       "      <td>2025_3479_3480</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65341 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID  Pred\n",
       "66066   2025_3101_3102   0.5\n",
       "66067   2025_3101_3103   0.5\n",
       "66068   2025_3101_3104   0.5\n",
       "66069   2025_3101_3105   0.5\n",
       "66070   2025_3101_3106   0.5\n",
       "...                ...   ...\n",
       "131402  2025_3477_3479   0.5\n",
       "131403  2025_3477_3480   0.5\n",
       "131404  2025_3478_3479   0.5\n",
       "131405  2025_3478_3480   0.5\n",
       "131406  2025_3479_3480   0.5\n",
       "\n",
       "[65341 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[66066:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "886c8553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>LowerTeamID</th>\n",
       "      <th>HigherTeamID</th>\n",
       "      <th>window_score_avg_diff</th>\n",
       "      <th>window_FG_pct_diff</th>\n",
       "      <th>window_3P_pct_diff</th>\n",
       "      <th>window_FT_pct_diff</th>\n",
       "      <th>window_off_eff_diff</th>\n",
       "      <th>window_Ast_avg_diff</th>\n",
       "      <th>window_TO_avg_diff</th>\n",
       "      <th>window_Stl_avg_diff</th>\n",
       "      <th>window_Blk_avg_diff</th>\n",
       "      <th>window_PF_avg_diff</th>\n",
       "      <th>window_OR_avg_diff</th>\n",
       "      <th>window_DR_avg_diff</th>\n",
       "      <th>window_clutch_count_diff</th>\n",
       "      <th>window_clutch_win_pct_diff</th>\n",
       "      <th>window_clutch_margin_avg_diff</th>\n",
       "      <th>window_clutch_score_avg_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66066</th>\n",
       "      <td>2025_3101_3102</td>\n",
       "      <td>2025</td>\n",
       "      <td>3101</td>\n",
       "      <td>3102</td>\n",
       "      <td>-2.285714</td>\n",
       "      <td>-0.006437</td>\n",
       "      <td>-0.052611</td>\n",
       "      <td>-0.031841</td>\n",
       "      <td>-0.045794</td>\n",
       "      <td>-2.142857</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>-2.428571</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66067</th>\n",
       "      <td>2025_3101_3103</td>\n",
       "      <td>2025</td>\n",
       "      <td>3101</td>\n",
       "      <td>3103</td>\n",
       "      <td>11.285714</td>\n",
       "      <td>0.046558</td>\n",
       "      <td>0.072054</td>\n",
       "      <td>0.065834</td>\n",
       "      <td>0.120036</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>-3.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66068</th>\n",
       "      <td>2025_3101_3104</td>\n",
       "      <td>2025</td>\n",
       "      <td>3101</td>\n",
       "      <td>3104</td>\n",
       "      <td>-14.428571</td>\n",
       "      <td>-0.064375</td>\n",
       "      <td>-0.138114</td>\n",
       "      <td>-0.033201</td>\n",
       "      <td>-0.132524</td>\n",
       "      <td>-2.428571</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>-3.142857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>-4.571429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66069</th>\n",
       "      <td>2025_3101_3105</td>\n",
       "      <td>2025</td>\n",
       "      <td>3101</td>\n",
       "      <td>3105</td>\n",
       "      <td>-2.714286</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.020909</td>\n",
       "      <td>0.077781</td>\n",
       "      <td>-0.029957</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66070</th>\n",
       "      <td>2025_3101_3106</td>\n",
       "      <td>2025</td>\n",
       "      <td>3101</td>\n",
       "      <td>3106</td>\n",
       "      <td>12.714286</td>\n",
       "      <td>0.060578</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>-0.057767</td>\n",
       "      <td>0.161730</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.571429</td>\n",
       "      <td>-2.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  Season  LowerTeamID  HigherTeamID  \\\n",
       "66066  2025_3101_3102    2025         3101          3102   \n",
       "66067  2025_3101_3103    2025         3101          3103   \n",
       "66068  2025_3101_3104    2025         3101          3104   \n",
       "66069  2025_3101_3105    2025         3101          3105   \n",
       "66070  2025_3101_3106    2025         3101          3106   \n",
       "\n",
       "       window_score_avg_diff  window_FG_pct_diff  window_3P_pct_diff  \\\n",
       "66066              -2.285714           -0.006437           -0.052611   \n",
       "66067              11.285714            0.046558            0.072054   \n",
       "66068             -14.428571           -0.064375           -0.138114   \n",
       "66069              -2.714286           -0.021948           -0.020909   \n",
       "66070              12.714286            0.060578            0.009091   \n",
       "\n",
       "       window_FT_pct_diff  window_off_eff_diff  window_Ast_avg_diff  \\\n",
       "66066           -0.031841            -0.045794            -2.142857   \n",
       "66067            0.065834             0.120036             4.714286   \n",
       "66068           -0.033201            -0.132524            -2.428571   \n",
       "66069            0.077781            -0.029957             2.857143   \n",
       "66070           -0.057767             0.161730             3.285714   \n",
       "\n",
       "       window_TO_avg_diff  window_Stl_avg_diff  window_Blk_avg_diff  \\\n",
       "66066            5.285714             1.285714             0.000000   \n",
       "66067           -3.142857             2.000000             1.428571   \n",
       "66068            1.428571             0.857143            -1.285714   \n",
       "66069            1.000000            -1.000000             0.285714   \n",
       "66070           -5.000000             0.714286             0.000000   \n",
       "\n",
       "       window_PF_avg_diff  window_OR_avg_diff  window_DR_avg_diff  \\\n",
       "66066           -1.285714            0.571429           -2.428571   \n",
       "66067           -2.000000           -4.000000           -1.285714   \n",
       "66068           -3.142857            0.714286           -4.571429   \n",
       "66069           -1.000000           -1.000000            0.571429   \n",
       "66070           -4.571429           -2.142857            0.285714   \n",
       "\n",
       "       window_clutch_count_diff  window_clutch_win_pct_diff  \\\n",
       "66066                      -2.0                         0.0   \n",
       "66067                       2.0                         0.5   \n",
       "66068                       1.0                        -0.5   \n",
       "66069                       1.0                        -0.5   \n",
       "66070                       0.0                         0.0   \n",
       "\n",
       "       window_clutch_margin_avg_diff  window_clutch_score_avg_diff  \n",
       "66066                            0.0                         -19.0  \n",
       "66067                            0.0                          52.5  \n",
       "66068                           -3.0                         -35.5  \n",
       "66069                           -3.0                         -17.5  \n",
       "66070                           -1.0                          -8.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_2025.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad51c941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset shape: (65341, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test dataset shape:\", test_dataset_2025.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28a7e668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 7_game_window_test_dataset_2025.csv\n"
     ]
    }
   ],
   "source": [
    "test_dataset_2025.to_csv(\"7_game_window_test_dataset_2025_women.csv\", index=False)\n",
    "print(\"Saved 7_game_window_test_dataset_2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7afe2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
